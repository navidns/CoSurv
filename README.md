# CoSurv
CoSurv: A Collaborative Framework for Survival Analysis in Healthcare

## All the experminets code are available in Experiments directory. ##

# A Peer-Driven Approach to Model Aggregation for Enhanced Trust in Federated Learning

## Overview

This repository contains the implementation of a robust trust-based framework for federated learning, specifically designed for healthcare applications. Our approach leverages decentralized, peer-driven trust feedback to dynamically weight client contributions during model aggregation. This mechanism mitigates the impact of noisy or adversarial updates while promoting fairness among collaborating institutions. The provided code includes synthetic data generation, trust evaluation, noise injection, clustering-based aggregation, and convergence analysis experiments.

## Project Structure
.
├── Data
│   └── ...            # (Datasets or generated data files)
├── Experiments
│   ├── EXP1_3_FSA_CUDA.ipynb         # Experiment 1: Parameter testing (alpha, epsilon, lambda)
│   └── EXP_Comparison_FSA_CUDA.ipynb # Experiment 2: Comparison with FLTrust
├── peer_to_peer_federated_learning.egg-info  # Python packaging metadata
├── src
│   └── ...            # (Source code for federated learning, trust mechanisms, etc.)
├── tests
│   └── ...            # (Unit tests and integration tests)
├── venv
│   └── ...            # (Local Python virtual environment)
├── .DS_Store          # (macOS system file, may be ignored)
├── README.md          # This file: instructions and project overview
├── requirements.txt   # Python dependencies
└── setup.py           # Setup script for installing the project as a Python package


## Description

1. Data:
   Contains datasets or generated data for experiments.

2. Experiments:
   - EXP1_3_FSA_CUDA.ipynb: Parameter testing (e.g., alpha, epsilon_max, lambda).
   - EXP_Comparison_FSA_CUDA.ipynb: Comparison of our approach against FLTrust.

3. peer_to_peer_federated_learning.egg-info:
   Python packaging metadata (generated by setuptools).

4. src:
   Source code for:
     - Trust-based aggregation and peer feedback mechanisms.
     - Clustering logic for feature completeness and risk alignment.
     - Noise injection strategies for adversarial scenarios.

5. tests:
   Contains test scripts to validate functionality and ensure correctness.

6. venv:
   Local Python virtual environment (optional), typically excluded from version control.

7. requirements.txt:
   Specifies Python dependencies needed to run the code.

8. setup.py:
   Allows you to install the repository as a Python package.

9. README.md:
   Provides high-level instructions on how to set up the environment, run experiments, and reproduce results.

## Usage

For convenience, all main experiments are in the `Experiments` folder:
- **EXP1_3_FSA_CUDA.ipynb**: Explore the effect of parameters like alpha (learning rate for trust), epsilon_max (noise injection limit), and lambda (clustering weight).
- **EXP_Comparison_FSA_CUDA.ipynb**: Compare our trust-based federated survival analysis approach with a FLTrust baseline.

To run experiments:
1. Clone this repository.
2. Create/activate a virtual environment (optional but recommended).
3. Install dependencies via `pip install -r requirements.txt`.
4. Navigate to the `Experiments` folder and open the desired `.ipynb` notebook in Jupyter or another environment that supports notebooks.
5. Adjust parameters if needed, then run the notebook cells to replicate our results.

For further details, please consult the main `README.md` file and the code comments within each notebook.
